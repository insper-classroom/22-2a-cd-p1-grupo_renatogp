{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "890a334b",
   "metadata": {},
   "source": [
    "___\n",
    "# Insper - Ciência dos Dados - Projeto 1\n",
    "\n",
    "# Obtenção das notícias\n",
    "\n",
    "Utilize este notebook para **baixar notícias** sobre algum assunto de seu interesse.\n",
    "\n",
    "As notícias serão automaticamente baixadas do site https://www.moneytimes.com.br/ utilizando o termo de busca informado por você!\n",
    "\n",
    "Será gerado um arquivo `dados.xlsx` contendo as informações disponíveis para o projeto.\n",
    "\n",
    "## Preparação do ambiente no jupyter\n",
    "\n",
    "Vamos importar algumas bibliotecas e definir algumas funções úteis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f3e4318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import random\n",
    "import time\n",
    "from math import floor\n",
    "\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "277c5131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caso alguma biblioteca estaja ausente, descomente e instale com pip\n",
    "# !pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "712e0b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_primeiro_paragrafo(content):\n",
    "    \n",
    "    soup = BeautifulSoup(content, 'html.parser')    \n",
    "    single__text = soup.find('div', class_='single__text')\n",
    "    prim_parag = single__text.find('p').text\n",
    "    \n",
    "    return prim_parag\n",
    "    \n",
    "    \n",
    "def parse_result(content, page=1):\n",
    "    \n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "    lista_tag_noticia = soup.find_all('div', class_='news-item')\n",
    "\n",
    "    lista_categoria = []\n",
    "    lista_titulo = []\n",
    "    lista_prim_parag = []\n",
    "    lista_data = []\n",
    "\n",
    "    for i in range(0, len(lista_tag_noticia)-1):\n",
    "        tag_noticia = lista_tag_noticia[i]\n",
    "\n",
    "        categoria = tag_noticia.find('div', class_='news-item__category').text\n",
    "        categoria = categoria.replace('\\n', '')\n",
    "        categoria = categoria.replace('\\t', '')\n",
    "        lista_categoria.append(categoria)\n",
    "\n",
    "        tag_titulo = tag_noticia.find('h2', class_='news-item__title')\n",
    "        titulo = tag_titulo.text\n",
    "        lista_titulo.append(titulo)\n",
    "        \n",
    "        link_noticia = tag_titulo.find('a')['href']\n",
    "        content_noticia = get_content(link_noticia)\n",
    "        prim_parag = parse_primeiro_paragrafo(content_noticia)\n",
    "        lista_prim_parag.append(prim_parag)\n",
    "\n",
    "        data_hora = tag_noticia.find('span', class_='date').text\n",
    "        lista_data.append(data_hora)\n",
    "\n",
    "    df = pd.DataFrame({'Categoria': lista_categoria,\n",
    "                       'Titulo': lista_titulo,\n",
    "                       'PrimeiroParag': lista_prim_parag,\n",
    "                       'Data': lista_data,\n",
    "                       'Pagina': page,\n",
    "                       'Target': None\n",
    "                  })\n",
    "    return df\n",
    "    \n",
    "def get_content(url):\n",
    "    headers = ({'User-Agent':\n",
    "            'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36'})\n",
    "    \n",
    "    resposta = requests.get(url=url, headers=headers, timeout=30)\n",
    "    resposta.encoding = 'utf-8'\n",
    "    \n",
    "    return resposta.text\n",
    "\n",
    "def get_news_page(word, page):\n",
    "    url = f'https://www.moneytimes.com.br/page/{page}/?s={word}'\n",
    "    content = get_content(url)\n",
    "    df_res = parse_result(content, page)\n",
    "    return df_res\n",
    "\n",
    "def get_df_news(word, n_news=500):\n",
    "    page = 0\n",
    "    news_per_page = 10\n",
    "    \n",
    "    print('\\nProgresso:')\n",
    "    n_max_pages = n_news//news_per_page\n",
    "    prog_bar = IntProgress(min=0, max=n_max_pages)\n",
    "    display(prog_bar)\n",
    "\n",
    "\n",
    "    while True:\n",
    "        page = page + 1\n",
    "        df_aux = get_news_page(word, page)\n",
    "        \n",
    "        if page==1:\n",
    "            df = df_aux\n",
    "        else:\n",
    "            df = pd.concat([df, df_aux], ignore_index=True)\n",
    "        \n",
    "        prog_bar.value += 1\n",
    "        \n",
    "        if page==n_max_pages:\n",
    "            break\n",
    "            \n",
    "        sec_sleep = random.randint(2, 5)\n",
    "        time.sleep(sec_sleep)\n",
    "            \n",
    "    return df\n",
    "\n",
    "def get_news(word, n_news=500, perc_train=0.6):\n",
    "       \n",
    "    if not os.path.isfile('../../data/dados.xlsx'):\n",
    "        \n",
    "        print(f'Ok! Vou baixar notícias sobre o termo {word} no MoneyTimes.com.br!')\n",
    "        print('\\nAguarde... Este processo pode demorar alguns minutos!')\n",
    "        \n",
    "        df = get_df_news(word, n_news)\n",
    "        df = df.sample(frac=1.0)\n",
    "    \n",
    "        writer = pd.ExcelWriter('../../data/dados.xlsx')\n",
    "        \n",
    "        n_real = len(df)\n",
    "        n_treino = floor(n_real * perc_train)\n",
    "\n",
    "        dft = df.iloc[:n_treino]\n",
    "        dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "        dfc = df.iloc[n_treino:]\n",
    "        dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "        writer.save()\n",
    "        \n",
    "        print('Processo finalizado!')\n",
    "        print('\\nGeramos um arquivo chamado dados.xlsx na pasta data, confira!')\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        raise Exception('Arquivo dados.xlsx já existe na pasta data! Apague o arquivo caso queira gerar novamente!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8354e9e2",
   "metadata": {},
   "source": [
    "## Defina o seu assunto\n",
    "\n",
    "Defina um assunto sobre o qual gostaria de encontrar notícias para o Projeto 1.\n",
    "\n",
    "Exemplos:\n",
    "- soja\n",
    "- nft\n",
    "- ministro\n",
    "- dólar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41cf1c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quer pesquisar notícias de qual assunto?!\n",
    "# Defina nesta string!\n",
    "assunto_noticia = 'dólar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b6c6965",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(assunto_noticia.strip()) == 0:\n",
    "    raise Exception('Você precisa definir o assunto das notícias a serem baixadas na variável assunto_noticia!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e88331",
   "metadata": {},
   "source": [
    "## Defina a quantidade de notícias\n",
    "\n",
    "Defina a quantidade de notícias a serem baixadas. A quantidade final retornada pode ser inferior ao desejado caso o seu assunto não seja muito abordado pelo MoneyTimes. Se isto ocorrer, escolha outro assunto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34adbf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qual a quantidade máxima desejada de notícias?! Altere aqui\n",
    "qtde_noticia = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ab079ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "if qtde_noticia <= 0:\n",
    "    raise Exception('Você precisa definir a quantidade de notícias!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89177fc",
   "metadata": {},
   "source": [
    "## Obtenção das notícias\n",
    "\n",
    "Execute a próxima célula. Ela irá construir uma base de dados de notícias sobre o seu assunto de interesse!\n",
    "\n",
    "Este processo poderá demorar alguns minutos. Quando ele finalizar, será gerado um arquivo `dados.xlsx` com as notícias!\n",
    "\n",
    "Pontos de atenção:\n",
    "- Confira se a quantidade de notícias encontradas foi suficiente (conforme enunciado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1de439f",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Arquivo dados.xlsx já existe na pasta data! Apague o arquivo caso queira gerar novamente!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\bebec\\OneDrive\\Área de Trabalho\\INSPER\\CDADOS\\CD22-2\\projeto01\\22-2a-cd-p1-grupo_renatogp\\notebooks\\scraping\\baixar_base_moneytimes.ipynb Célula: 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/bebec/OneDrive/%C3%81rea%20de%20Trabalho/INSPER/CDADOS/CD22-2/projeto01/22-2a-cd-p1-grupo_renatogp/notebooks/scraping/baixar_base_moneytimes.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m get_news(assunto_noticia, n_news\u001b[39m=\u001b[39;49mqtde_noticia, perc_train\u001b[39m=\u001b[39;49m\u001b[39m0.6\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\bebec\\OneDrive\\Área de Trabalho\\INSPER\\CDADOS\\CD22-2\\projeto01\\22-2a-cd-p1-grupo_renatogp\\notebooks\\scraping\\baixar_base_moneytimes.ipynb Célula: 12\u001b[0m in \u001b[0;36mget_news\u001b[1;34m(word, n_news, perc_train)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/bebec/OneDrive/%C3%81rea%20de%20Trabalho/INSPER/CDADOS/CD22-2/projeto01/22-2a-cd-p1-grupo_renatogp/notebooks/scraping/baixar_base_moneytimes.ipynb#X14sZmlsZQ%3D%3D?line=117'>118</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mGeramos um arquivo chamado dados.xlsx na pasta data, confira!\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/bebec/OneDrive/%C3%81rea%20de%20Trabalho/INSPER/CDADOS/CD22-2/projeto01/22-2a-cd-p1-grupo_renatogp/notebooks/scraping/baixar_base_moneytimes.ipynb#X14sZmlsZQ%3D%3D?line=119'>120</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/bebec/OneDrive/%C3%81rea%20de%20Trabalho/INSPER/CDADOS/CD22-2/projeto01/22-2a-cd-p1-grupo_renatogp/notebooks/scraping/baixar_base_moneytimes.ipynb#X14sZmlsZQ%3D%3D?line=121'>122</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mArquivo dados.xlsx já existe na pasta data! Apague o arquivo caso queira gerar novamente!\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mException\u001b[0m: Arquivo dados.xlsx já existe na pasta data! Apague o arquivo caso queira gerar novamente!"
     ]
    }
   ],
   "source": [
    "get_news(assunto_noticia, n_news=qtde_noticia, perc_train=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c701c31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "cdcf8f726040b12d3568ceac60b6ca4b3e4ab6e019e8147e37d5985e50983e9a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
